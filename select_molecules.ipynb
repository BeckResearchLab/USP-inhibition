{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pphilip/miniconda2/envs/my-rdkit-env/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "/home/pphilip/miniconda2/envs/my-rdkit-env/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pd.set_option('precision', 3)\n",
    "TARGET_COLUMN = 'Activity_Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_nan_infinite(dataframe):\n",
    "    \"\"\"\n",
    "    Replacing NaN and infinite values from the dataframe with zeros.\n",
    "    :param dataframe: Dataframe containing NaN and infinite values.\n",
    "    :return data: Data with no NaN or infinite values.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = dataframe.fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "def choose_features(x_train, y_train, x_test, column_names):\n",
    "    \"\"\"\n",
    "    Selecting the features of high importance to reduce feature space.\n",
    "    :param x_train: Training set of features.\n",
    "    :param x_test: Test set of features.\n",
    "    :param y_train: Training target values\n",
    "    :param column_names: Names of columns in x\n",
    "    \"\"\"\n",
    "\n",
    "    # Random forest feature importance\n",
    "    clf = RandomForestRegressor(n_jobs=-1, random_state=1, n_estimators=20, max_depth=10)\n",
    "    # Random state has int value for non-random sampling\n",
    "    clf.fit(x_train, y_train)\n",
    "    feature_importance = clf.feature_importances_\n",
    "    scores_table = pd.DataFrame({'feature': column_names, 'scores':\n",
    "                                 feature_importance}).sort_values(by=['scores'], ascending=False)\n",
    "    scores = scores_table['scores'].tolist()\n",
    "    n_features = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    for n in n_features:\n",
    "        feature_scores = scores_table['feature'].tolist()\n",
    "        selected_features = feature_scores[:n]\n",
    "        x_train = pd.DataFrame(x_train, columns=column_names)\n",
    "        desired_x_train = x_train[selected_features]\n",
    "        x_test = pd.DataFrame(x_test, columns=column_names)\n",
    "        desired_x_test = x_test[selected_features]\n",
    "\n",
    "        desired_x_train.to_csv('./data/select_x_train_postprocessing_rfr_%d.csv' % n)\n",
    "        desired_x_test.to_csv('./data/select_x_test_postprocessing_rfr_%d.csv' % n)\n",
    "    pd.DataFrame(scores).to_csv('./data/select_feature_scores_rfr.csv')\n",
    "\n",
    "    return\n",
    "\n",
    "def run_models(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Driving all machine learning models as parallel processes.\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model_choice = int(input(\"Type your choice of model to be run:\" + \"\\n\" +\n",
    "                             \"1 for Linear Regression\" + \"\\n\" +\n",
    "                             \"2 for Neural Network\" + \"\\n\" +\n",
    "                             \"3 for Support Vector Machine\" + \"\\n\" +\n",
    "                             \"4 for Decision Tree\" + \"\\n\" +\n",
    "                             \"5 for Ridge Regression\" + \"\\n\" +\n",
    "                             \"6 for Bayesian Ridge Regression\" + \"\\n\" +\n",
    "                             \"7 for Lasso:\" + \"\\n\" +\n",
    "                             \"8 for Random Forest Regressor:\" + \"\\n\"\n",
    "                             ))\n",
    "    if model_choice == 1:\n",
    "        build_linear(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 2:\n",
    "        build_nn(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 3:\n",
    "        build_svm(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 4:\n",
    "        build_tree(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 5:\n",
    "        build_ridge(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 6:\n",
    "        build_bayesian_rr(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 7:\n",
    "        build_lasso(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 8:\n",
    "        build_forest(x_train, y_train, x_test, y_test, n_features)\n",
    "    else:\n",
    "        print(\"Please choose from list of available models only\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_linear(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a decision trees regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_lr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_nn(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a regression neural network model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    net = NeuralNet(layers=[('input', InputLayer),\n",
    "                            ('hidden0', DenseLayer),\n",
    "                            ('hidden1', DenseLayer),\n",
    "                            ('output', DenseLayer)],\n",
    "                    input_shape=(None, x_train.shape[1]),  # Number of i/p nodes = number of columns in x\n",
    "                    hidden0_num_units=15,\n",
    "                    hidden0_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    hidden1_num_units=17,\n",
    "                    hidden1_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    output_num_units=1,  # Number of o/p nodes = number of columns in y\n",
    "                    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    max_epochs=100,\n",
    "                    update_learning_rate=0.01,\n",
    "                    regression=True,\n",
    "                    verbose=0)\n",
    "\n",
    "    # Finding the optimal set of params for each variable in the training of the neural network\n",
    "    param_dist = {'hidden0_num_units':sp_randint(3, 30), 'hidden1_num_units':sp_randint(3, 30)}\n",
    "    clf = RandomizedSearchCV(estimator=net, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_nn_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(net, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_svm(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a support vector regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    clf = LinearSVR(random_state=1, dual=False, epsilon=0,\n",
    "                    loss='squared_epsilon_insensitive')\n",
    "    # Random state has int value for non-random sampling\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_svm_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_tree(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a decision trees regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model = DecisionTreeRegressor()\n",
    "    param_dist = {'max_depth': sp_randint(1, 15),\n",
    "                  'min_samples_split': sp_randint(2, 15)}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_dt_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_ridge(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a ridge regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = Ridge()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_rr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_bayesian_rr(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a Bayesian ridge regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "    # Optimal ridge regression alpha value from CV\n",
    "    ridge_alpha = clf.alpha_\n",
    "\n",
    "    with open('./trained_networks/select_brr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(ridge_alpha, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_lasso(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a Lasso linear model with cross validation from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model = Lasso(random_state=1, tol=0.001)\n",
    "    # Random state has int value for non-random sampling\n",
    "    param_dist = {'alpha': np.arange( 0.0001, 1, 0.001 ).tolist()}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=20, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_lasso_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_forest(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a random forest regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor()\n",
    "    param_dist = {'max_depth': sp_randint(1, 15),\n",
    "                  'min_samples_split': sp_randint(2, 15)}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/select_rfr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "    return\n",
    "\n",
    "def select_results():\n",
    "    df_mean_abs = pd.DataFrame()\n",
    "    df_mean_sq = pd.DataFrame()\n",
    "    df_median_abs = pd.DataFrame()\n",
    "    df_r2 = pd.DataFrame()\n",
    "    df_exp_var_score = pd.DataFrame()\n",
    "    lists = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    \n",
    "    for n_features in lists:\n",
    "        with open('./trained_networks/select_lr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear Regression', '%d' % n_features,  mean_abs)\n",
    "            df_mean_sq.set_value('Linear Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_nn_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            net = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_nn = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Neural Network', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Neural Network', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Neural Network', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Neural Network', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Neural Network', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_svm_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_svm = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear SVR', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Linear SVR', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear SVR', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear SVR', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear SVR', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_dt_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_dt = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Decision Tree', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Decision Tree', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Decision Tree', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Decision Tree', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Decision Tree', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_rr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_rr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_brr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_brr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Bayesian Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Bayesian Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "            \n",
    "        with open('./trained_networks/select_lasso_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Lasso', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Lasso', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Lasso', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Lasso', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Lasso', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/select_rfr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Random Forest regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Random Forest regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Random Forest regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Random Forest regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Random Forest regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "    return df_mean_abs, df_mean_sq, df_median_abs, df_r2, df_exp_var_score\n",
    "\n",
    "def all_results():\n",
    "    df_mean_abs = pd.DataFrame()\n",
    "    df_mean_sq = pd.DataFrame()\n",
    "    df_median_abs = pd.DataFrame()\n",
    "    df_r2 = pd.DataFrame()\n",
    "    df_exp_var_score = pd.DataFrame()\n",
    "    lists = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    \n",
    "    for n_features in lists:\n",
    "        with open('./trained_networks/all_lr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear Regression', '%d' % n_features,  mean_abs)\n",
    "            df_mean_sq.set_value('Linear Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_nn_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            net = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_nn = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Neural Network', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Neural Network', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Neural Network', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Neural Network', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Neural Network', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_svm_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_svm = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear SVR', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Linear SVR', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear SVR', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear SVR', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear SVR', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_dt_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_dt = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Decision Tree', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Decision Tree', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Decision Tree', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Decision Tree', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Decision Tree', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_rr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_rr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_brr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_brr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Bayesian Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Bayesian Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "            \n",
    "        with open('./trained_networks/all_lasso_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Lasso', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Lasso', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Lasso', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Lasso', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Lasso', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_rfr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Random Forest regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Random Forest regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Random Forest regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Random Forest regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Random Forest regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "    return df_mean_abs, df_mean_sq, df_median_abs, df_r2, df_exp_var_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://s3-us-west-2.amazonaws.com/'\n",
    "                 'pphilip-usp-inhibition/data/df_preprocessing.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_df = df.loc[df[TARGET_COLUMN] > 0]\n",
    "select_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Copying column names to use after np array manipulation\n",
    "all_headers = list(select_df.columns.values)\n",
    "x_headers = list(select_df.columns.values)[:-1]\n",
    "\n",
    "# Train, validation and test split\n",
    "df_train, df_test = model_selection.train_test_split(select_df, test_size=0.25)\n",
    "# Reassign column name and index after randomized split\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)\n",
    "df_train = pd.DataFrame(df_train, columns=all_headers)\n",
    "df_test = pd.DataFrame(df_test, columns=all_headers)\n",
    "\n",
    "# Remove the classification column from the dataframe\n",
    "x_train = df_train.drop(TARGET_COLUMN, axis=1)\n",
    "x_test = df_test.drop(TARGET_COLUMN, axis=1)\n",
    "y_train = df_train[TARGET_COLUMN]\n",
    "y_test = df_test[TARGET_COLUMN]\n",
    "\n",
    "# Checking dataframe for NaN and infinite values\n",
    "x_train = change_nan_infinite(x_train)\n",
    "y_train = change_nan_infinite(y_train)\n",
    "x_test = change_nan_infinite(x_test)\n",
    "y_test = change_nan_infinite(y_test)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns=[TARGET_COLUMN])\n",
    "y_test = pd.DataFrame(y_test, columns=[TARGET_COLUMN])\n",
    "\n",
    "y_train.to_csv('./data/select_y_train_postprocessing.csv')\n",
    "y_test.to_csv('./data/select_y_test_postprocessing.csv')\n",
    "\n",
    "# Transform all column values to mean 0 and unit variance\n",
    "clf = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = clf.transform(x_train)\n",
    "x_test = clf.transform(x_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Feature selection and feature importance plot\n",
    "choose_features(x_train, y_train, x_test, x_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = int(input(\"Choose the number of features to be used in the model\" + \"\\n\" +\n",
    "                       \"Pick from 25, 50, 75, 100, 150, 200, 250, 300\" + \"\\n\"))\n",
    "x_train = pd.read_csv('./data/select_x_train_postprocessing_rfr_%d.csv' % n_features)\n",
    "x_test = pd.read_csv('./data/select_x_test_postprocessing_rfr_%d.csv' % n_features)\n",
    "y_train = pd.read_csv('./data/select_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/select_y_test_postprocessing.csv')\n",
    "x_train.drop(x_train.columns[0], axis=1, inplace=True)\n",
    "x_test.drop(x_test.columns[0], axis=1, inplace=True)\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "\n",
    "print(\"Generating models\")\n",
    "run_models(np.array(x_train), np.array(y_train).ravel(), np.array(x_test), np.array(y_test).ravel(), n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all_mean_abs, df_all_mean_sq, df_all_median_abs, df_all_r2, df_all_exp_var_score = all_results()\n",
    "df_select_mean_abs, df_select_mean_sq, df_select_median_abs, df_select_r2, df_select_exp_var_score = select_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1.451</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.471</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.468</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>1.413</td>\n",
       "      <td>1.398</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.431</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Neural Network             1.678  1.678  1.678  1.678  1.678  1.678  1.678   \n",
       "Linear SVR                 1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Decision Tree              1.451  1.470  1.470  1.470  1.470  1.456  1.456   \n",
       "Ridge Regression           1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Bayesian Ridge Regression  1.464  1.463  1.463  1.462  1.463  1.464  1.465   \n",
       "Lasso                      1.471  1.463  1.464  1.468  1.462  1.463  1.461   \n",
       "Random Forest regression   1.413  1.398  1.420  1.416  1.431  1.420  1.416   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          1.473  \n",
       "Neural Network             1.678  \n",
       "Linear SVR                 1.473  \n",
       "Decision Tree              1.448  \n",
       "Ridge Regression           1.473  \n",
       "Bayesian Ridge Regression  1.466  \n",
       "Lasso                      1.464  \n",
       "Random Forest regression   1.420  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_mean_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>15.075</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.176</td>\n",
       "      <td>15.176</td>\n",
       "      <td>15.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.084</td>\n",
       "      <td>15.050</td>\n",
       "      <td>15.022</td>\n",
       "      <td>14.994</td>\n",
       "      <td>14.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>15.211</td>\n",
       "      <td>15.142</td>\n",
       "      <td>15.153</td>\n",
       "      <td>15.174</td>\n",
       "      <td>15.125</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.118</td>\n",
       "      <td>15.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>14.608</td>\n",
       "      <td>14.504</td>\n",
       "      <td>14.783</td>\n",
       "      <td>14.692</td>\n",
       "      <td>14.752</td>\n",
       "      <td>14.631</td>\n",
       "      <td>14.689</td>\n",
       "      <td>14.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               25      50      75     100     150     200  \\\n",
       "Linear Regression          15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Neural Network             15.349  15.349  15.349  15.349  15.349  15.349   \n",
       "Linear SVR                 15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Decision Tree              15.075  15.241  15.241  15.241  15.241  15.176   \n",
       "Ridge Regression           15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Bayesian Ridge Regression  15.164  15.130  15.115  15.084  15.050  15.022   \n",
       "Lasso                      15.211  15.142  15.153  15.174  15.125  15.130   \n",
       "Random Forest regression   14.608  14.504  14.783  14.692  14.752  14.631   \n",
       "\n",
       "                              250     300  \n",
       "Linear Regression          14.980  14.964  \n",
       "Neural Network             15.349  15.349  \n",
       "Linear SVR                 14.980  14.961  \n",
       "Decision Tree              15.176  15.202  \n",
       "Ridge Regression           14.980  14.962  \n",
       "Bayesian Ridge Regression  14.994  14.972  \n",
       "Lasso                      15.118  15.144  \n",
       "Random Forest regression   14.689  14.728  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_mean_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Neural Network             1.000  1.000  1.000  1.000  1.000  1.000  1.000   \n",
       "Linear SVR                 0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Decision Tree              0.490  0.547  0.547  0.547  0.547  0.490  0.490   \n",
       "Ridge Regression           0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Bayesian Ridge Regression  0.726  0.721  0.722  0.713  0.709  0.708  0.707   \n",
       "Lasso                      0.737  0.726  0.727  0.734  0.719  0.719  0.717   \n",
       "Random Forest regression   0.553  0.527  0.546  0.552  0.581  0.542  0.542   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.711  \n",
       "Neural Network             1.000  \n",
       "Linear SVR                 0.711  \n",
       "Decision Tree              0.632  \n",
       "Ridge Regression           0.711  \n",
       "Bayesian Ridge Regression  0.709  \n",
       "Lasso                      0.723  \n",
       "Random Forest regression   0.556  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_median_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Neural Network            -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003   \n",
       "Linear SVR                 0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Decision Tree              0.020  0.009  0.009  0.009  0.009  0.013  0.013   \n",
       "Ridge Regression           0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Bayesian Ridge Regression  0.014  0.016  0.017  0.019  0.021  0.023  0.025   \n",
       "Lasso                      0.011  0.016  0.015  0.013  0.017  0.016  0.017   \n",
       "Random Forest regression   0.050  0.057  0.039  0.045  0.041  0.049  0.045   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.027  \n",
       "Neural Network            -0.003  \n",
       "Linear SVR                 0.027  \n",
       "Decision Tree              0.012  \n",
       "Ridge Regression           0.027  \n",
       "Bayesian Ridge Regression  0.027  \n",
       "Lasso                      0.015  \n",
       "Random Forest regression   0.042  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Neural Network             0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "Linear SVR                 0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Decision Tree              0.020  0.009  0.009  0.009  0.009  0.013  0.013   \n",
       "Ridge Regression           0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Bayesian Ridge Regression  0.014  0.016  0.017  0.019  0.021  0.023  0.025   \n",
       "Lasso                      0.011  0.016  0.015  0.013  0.017  0.016  0.017   \n",
       "Random Forest regression   0.050  0.057  0.039  0.045  0.041  0.049  0.045   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.027  \n",
       "Neural Network             0.000  \n",
       "Linear SVR                 0.027  \n",
       "Decision Tree              0.012  \n",
       "Ridge Regression           0.027  \n",
       "Bayesian Ridge Regression  0.027  \n",
       "Lasso                      0.015  \n",
       "Random Forest regression   0.042  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_exp_var_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>6.405</td>\n",
       "      <td>6.384</td>\n",
       "      <td>6.357</td>\n",
       "      <td>6.337</td>\n",
       "      <td>6.276</td>\n",
       "      <td>6.268</td>\n",
       "      <td>6.253</td>\n",
       "      <td>6.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "      <td>14.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>6.405</td>\n",
       "      <td>6.384</td>\n",
       "      <td>6.356</td>\n",
       "      <td>6.337</td>\n",
       "      <td>6.276</td>\n",
       "      <td>6.267</td>\n",
       "      <td>6.247</td>\n",
       "      <td>6.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>6.463</td>\n",
       "      <td>6.489</td>\n",
       "      <td>6.463</td>\n",
       "      <td>6.465</td>\n",
       "      <td>6.465</td>\n",
       "      <td>6.463</td>\n",
       "      <td>6.463</td>\n",
       "      <td>6.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>6.405</td>\n",
       "      <td>6.384</td>\n",
       "      <td>6.356</td>\n",
       "      <td>6.337</td>\n",
       "      <td>6.276</td>\n",
       "      <td>6.266</td>\n",
       "      <td>6.247</td>\n",
       "      <td>6.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>6.406</td>\n",
       "      <td>6.384</td>\n",
       "      <td>6.355</td>\n",
       "      <td>6.345</td>\n",
       "      <td>6.304</td>\n",
       "      <td>6.288</td>\n",
       "      <td>6.273</td>\n",
       "      <td>6.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>6.413</td>\n",
       "      <td>6.413</td>\n",
       "      <td>6.378</td>\n",
       "      <td>6.345</td>\n",
       "      <td>6.278</td>\n",
       "      <td>6.268</td>\n",
       "      <td>6.281</td>\n",
       "      <td>6.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>6.334</td>\n",
       "      <td>6.294</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.344</td>\n",
       "      <td>6.367</td>\n",
       "      <td>6.345</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               25      50      75     100     150     200  \\\n",
       "Linear Regression           6.405   6.384   6.357   6.337   6.276   6.268   \n",
       "Neural Network             14.275  14.275  14.275  14.275  14.275  14.275   \n",
       "Linear SVR                  6.405   6.384   6.356   6.337   6.276   6.267   \n",
       "Decision Tree               6.463   6.489   6.463   6.465   6.465   6.463   \n",
       "Ridge Regression            6.405   6.384   6.356   6.337   6.276   6.266   \n",
       "Bayesian Ridge Regression   6.406   6.384   6.355   6.345   6.304   6.288   \n",
       "Lasso                       6.413   6.413   6.378   6.345   6.278   6.268   \n",
       "Random Forest regression    6.334   6.294   6.312   6.344   6.367   6.345   \n",
       "\n",
       "                              250     300  \n",
       "Linear Regression           6.253   6.262  \n",
       "Neural Network             14.275  14.275  \n",
       "Linear SVR                  6.247   6.256  \n",
       "Decision Tree               6.463   6.465  \n",
       "Ridge Regression            6.247   6.256  \n",
       "Bayesian Ridge Regression   6.273   6.269  \n",
       "Lasso                       6.281   6.346  \n",
       "Random Forest regression    6.374   6.374  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select_mean_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>81.188</td>\n",
       "      <td>80.801</td>\n",
       "      <td>80.604</td>\n",
       "      <td>80.264</td>\n",
       "      <td>79.336</td>\n",
       "      <td>79.221</td>\n",
       "      <td>79.143</td>\n",
       "      <td>79.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "      <td>287.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>81.188</td>\n",
       "      <td>80.801</td>\n",
       "      <td>80.603</td>\n",
       "      <td>80.262</td>\n",
       "      <td>79.338</td>\n",
       "      <td>79.200</td>\n",
       "      <td>79.077</td>\n",
       "      <td>79.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>82.855</td>\n",
       "      <td>82.251</td>\n",
       "      <td>82.855</td>\n",
       "      <td>82.384</td>\n",
       "      <td>82.384</td>\n",
       "      <td>82.855</td>\n",
       "      <td>82.855</td>\n",
       "      <td>82.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>81.188</td>\n",
       "      <td>80.801</td>\n",
       "      <td>80.603</td>\n",
       "      <td>80.262</td>\n",
       "      <td>79.340</td>\n",
       "      <td>79.198</td>\n",
       "      <td>79.072</td>\n",
       "      <td>79.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>81.126</td>\n",
       "      <td>80.629</td>\n",
       "      <td>80.306</td>\n",
       "      <td>80.174</td>\n",
       "      <td>79.538</td>\n",
       "      <td>79.328</td>\n",
       "      <td>79.102</td>\n",
       "      <td>79.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>81.201</td>\n",
       "      <td>80.956</td>\n",
       "      <td>80.385</td>\n",
       "      <td>80.212</td>\n",
       "      <td>79.348</td>\n",
       "      <td>79.195</td>\n",
       "      <td>79.193</td>\n",
       "      <td>79.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>76.645</td>\n",
       "      <td>75.487</td>\n",
       "      <td>76.521</td>\n",
       "      <td>78.174</td>\n",
       "      <td>78.872</td>\n",
       "      <td>76.120</td>\n",
       "      <td>77.208</td>\n",
       "      <td>79.215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                25       50       75      100      150  \\\n",
       "Linear Regression           81.188   80.801   80.604   80.264   79.336   \n",
       "Neural Network             287.633  287.633  287.633  287.633  287.633   \n",
       "Linear SVR                  81.188   80.801   80.603   80.262   79.338   \n",
       "Decision Tree               82.855   82.251   82.855   82.384   82.384   \n",
       "Ridge Regression            81.188   80.801   80.603   80.262   79.340   \n",
       "Bayesian Ridge Regression   81.126   80.629   80.306   80.174   79.538   \n",
       "Lasso                       81.201   80.956   80.385   80.212   79.348   \n",
       "Random Forest regression    76.645   75.487   76.521   78.174   78.872   \n",
       "\n",
       "                               200      250      300  \n",
       "Linear Regression           79.221   79.143   79.341  \n",
       "Neural Network             287.633  287.633  287.633  \n",
       "Linear SVR                  79.200   79.077   79.188  \n",
       "Decision Tree               82.855   82.855   82.384  \n",
       "Ridge Regression            79.198   79.072   79.190  \n",
       "Bayesian Ridge Regression   79.328   79.102   79.059  \n",
       "Lasso                       79.195   79.193   79.776  \n",
       "Random Forest regression    76.120   77.208   79.215  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select_mean_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5.184</td>\n",
       "      <td>5.257</td>\n",
       "      <td>5.243</td>\n",
       "      <td>5.275</td>\n",
       "      <td>5.186</td>\n",
       "      <td>5.150</td>\n",
       "      <td>5.155</td>\n",
       "      <td>5.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>5.184</td>\n",
       "      <td>5.256</td>\n",
       "      <td>5.243</td>\n",
       "      <td>5.274</td>\n",
       "      <td>5.177</td>\n",
       "      <td>5.150</td>\n",
       "      <td>5.131</td>\n",
       "      <td>5.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>4.650</td>\n",
       "      <td>5.423</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.409</td>\n",
       "      <td>4.409</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>5.184</td>\n",
       "      <td>5.256</td>\n",
       "      <td>5.246</td>\n",
       "      <td>5.276</td>\n",
       "      <td>5.180</td>\n",
       "      <td>5.155</td>\n",
       "      <td>5.115</td>\n",
       "      <td>5.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>5.189</td>\n",
       "      <td>5.261</td>\n",
       "      <td>5.258</td>\n",
       "      <td>5.299</td>\n",
       "      <td>5.220</td>\n",
       "      <td>5.203</td>\n",
       "      <td>5.148</td>\n",
       "      <td>5.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>5.170</td>\n",
       "      <td>5.184</td>\n",
       "      <td>5.242</td>\n",
       "      <td>5.300</td>\n",
       "      <td>5.191</td>\n",
       "      <td>5.186</td>\n",
       "      <td>5.179</td>\n",
       "      <td>5.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>4.655</td>\n",
       "      <td>4.651</td>\n",
       "      <td>4.667</td>\n",
       "      <td>4.770</td>\n",
       "      <td>4.787</td>\n",
       "      <td>4.716</td>\n",
       "      <td>4.695</td>\n",
       "      <td>4.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          5.184  5.257  5.243  5.275  5.186  5.150  5.155   \n",
       "Neural Network             9.000  9.000  9.000  9.000  9.000  9.000  9.000   \n",
       "Linear SVR                 5.184  5.256  5.243  5.274  5.177  5.150  5.131   \n",
       "Decision Tree              4.650  5.423  4.650  4.409  4.409  4.650  4.650   \n",
       "Ridge Regression           5.184  5.256  5.246  5.276  5.180  5.155  5.115   \n",
       "Bayesian Ridge Regression  5.189  5.261  5.258  5.299  5.220  5.203  5.148   \n",
       "Lasso                      5.170  5.184  5.242  5.300  5.191  5.186  5.179   \n",
       "Random Forest regression   4.655  4.651  4.667  4.770  4.787  4.716  4.695   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          5.153  \n",
       "Neural Network             9.000  \n",
       "Linear SVR                 5.156  \n",
       "Decision Tree              4.409  \n",
       "Ridge Regression           5.147  \n",
       "Bayesian Ridge Regression  5.150  \n",
       "Lasso                      5.244  \n",
       "Random Forest regression   4.748  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select_median_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-2.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.086</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.032  0.036  0.039  0.043  0.054  0.055  0.056   \n",
       "Neural Network            -2.430 -2.430 -2.430 -2.430 -2.430 -2.430 -2.430   \n",
       "Linear SVR                 0.032  0.036  0.039  0.043  0.054  0.056  0.057   \n",
       "Decision Tree              0.012  0.019  0.012  0.018  0.018  0.012  0.012   \n",
       "Ridge Regression           0.032  0.036  0.039  0.043  0.054  0.056  0.057   \n",
       "Bayesian Ridge Regression  0.033  0.038  0.042  0.044  0.051  0.054  0.057   \n",
       "Lasso                      0.032  0.035  0.041  0.043  0.054  0.056  0.056   \n",
       "Random Forest regression   0.086  0.100  0.087  0.068  0.059  0.092  0.079   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.054  \n",
       "Neural Network            -2.430  \n",
       "Linear SVR                 0.056  \n",
       "Decision Tree              0.018  \n",
       "Ridge Regression           0.056  \n",
       "Bayesian Ridge Regression  0.057  \n",
       "Lasso                      0.049  \n",
       "Random Forest regression   0.055  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.086</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.032  0.037  0.039  0.043  0.054  0.055  0.056   \n",
       "Neural Network             0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "Linear SVR                 0.032  0.037  0.039  0.043  0.054  0.056  0.057   \n",
       "Decision Tree              0.012  0.019  0.012  0.018  0.018  0.012  0.012   \n",
       "Ridge Regression           0.032  0.037  0.039  0.043  0.054  0.056  0.057   \n",
       "Bayesian Ridge Regression  0.033  0.039  0.042  0.044  0.052  0.054  0.057   \n",
       "Lasso                      0.032  0.035  0.041  0.044  0.054  0.056  0.056   \n",
       "Random Forest regression   0.086  0.100  0.088  0.068  0.060  0.093  0.080   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.054  \n",
       "Neural Network             0.000  \n",
       "Linear SVR                 0.056  \n",
       "Decision Tree              0.018  \n",
       "Ridge Regression           0.056  \n",
       "Bayesian Ridge Regression  0.057  \n",
       "Lasso                      0.049  \n",
       "Random Forest regression   0.056  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select_exp_var_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "select_means = df_select_mean_abs.mean(axis=1).tolist()\n",
    "select_std = df_select_mean_abs.std(axis=1).tolist()\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, select_means, width, color='r', yerr=select_std)\n",
    "all_means = df_all_mean_abs.mean(axis=1).tolist()\n",
    "all_std = df_all_mean_abs.std(axis=1).tolist()\n",
    "rects2 = ax.bar(ind + width, all_means, width, color='b', yerr=all_std)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Mean absolute error')\n",
    "ax.set_title('MAE by dataset and learning algorithm')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('LR', 'NN', 'SVR', 'DT', 'RR', 'BRR', 'Lasso', 'RFR'))\n",
    "ax.legend((rects1[0], rects2[0]), ('Active molecules', 'All molecules'))\n",
    "plt.savefig('./plots/mae.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "select_means = df_select_mean_sq.mean(axis=1).tolist()\n",
    "select_std = df_select_mean_sq.std(axis=1).tolist()\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, select_means, width, color='r', yerr=select_std)\n",
    "all_means = df_all_mean_sq.mean(axis=1).tolist()\n",
    "all_std = df_all_mean_sq.std(axis=1).tolist()\n",
    "rects2 = ax.bar(ind + width, all_means, width, color='b', yerr=all_std)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Mean square error')\n",
    "ax.set_title('MSE by dataset and learning algorithm')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('LR', 'NN', 'SVR', 'DT', 'RR', 'BRR', 'Lasso', 'RFR'))\n",
    "ax.legend((rects1[0], rects2[0]), ('Active molecules', 'All molecules'))\n",
    "plt.savefig('./plots/mse.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "select_means = df_select_median_abs.mean(axis=1).tolist()\n",
    "select_std = df_select_median_abs.std(axis=1).tolist()\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, select_means, width, color='r', yerr=select_std)\n",
    "all_means = df_all_median_abs.mean(axis=1).tolist()\n",
    "all_std = df_all_median_abs.std(axis=1).tolist()\n",
    "rects2 = ax.bar(ind + width, all_means, width, color='b', yerr=all_std)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Median absolute error')\n",
    "ax.set_title('MedAE by dataset and learning algorithm')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('LR', 'NN', 'SVR', 'DT', 'RR', 'BRR', 'Lasso', 'RFR'))\n",
    "ax.legend((rects1[0], rects2[0]), ('Active molecules', 'All molecules'))\n",
    "plt.savefig('./plots/medae.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "select_means = df_select_r2.mean(axis=1).tolist()\n",
    "select_std = df_select_r2.std(axis=1).tolist()\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, select_means, width, color='r', yerr=select_std)\n",
    "all_means = df_all_r2.mean(axis=1).tolist()\n",
    "all_std = df_all_r2.std(axis=1).tolist()\n",
    "rects2 = ax.bar(ind + width, all_means, width, color='b', yerr=all_std)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('R2 score')\n",
    "ax.set_title('R2 score by dataset and learning algorithm')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('LR', 'NN', 'SVR', 'DT', 'RR', 'BRR', 'Lasso', 'RFR'))\n",
    "ax.legend((rects1[0], rects2[0]), ('Active molecules', 'All molecules'))\n",
    "plt.savefig('./plots/r2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "select_means = df_select_exp_var_score.mean(axis=1).tolist()\n",
    "select_std = df_select_exp_var_score.std(axis=1).tolist()\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, select_means, width, color='r', yerr=select_std)\n",
    "all_means = df_all_exp_var_score.mean(axis=1).tolist()\n",
    "all_std = df_all_exp_var_score.std(axis=1).tolist()\n",
    "rects2 = ax.bar(ind + width, all_means, width, color='b', yerr=all_std)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Explained variance score')\n",
    "ax.set_title('EVS by dataset and learning algorithm')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('LR', 'NN', 'SVR', 'DT', 'RR', 'BRR', 'Lasso', 'RFR'))\n",
    "ax.legend((rects1[0], rects2[0]), ('Active molecules', 'All molecules'))\n",
    "plt.savefig('./plots/evs.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 300\n",
    "x_train = pd.read_csv('./data/select_x_train_postprocessing_rfr_%d.csv' % n_features)\n",
    "x_test = pd.read_csv('./data/select_x_test_postprocessing_rfr_%d.csv' % n_features)\n",
    "y_train = pd.read_csv('./data/select_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/select_y_test_postprocessing.csv')\n",
    "x_train.drop(x_train.columns[0], axis=1, inplace=True)\n",
    "x_test.drop(x_test.columns[0], axis=1, inplace=True)\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "plots.plot_features(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('./data/select_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/select_y_test_postprocessing.csv')\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "plots.plot_y_dist(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genalgo.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
