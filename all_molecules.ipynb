{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pphilip/miniconda2/envs/my-rdkit-env/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "/home/pphilip/miniconda2/envs/my-rdkit-env/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import lasagne\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "try:\n",
    "    import urllib.request as urllib2\n",
    "except ImportError:\n",
    "    import urllib2\n",
    "import random\n",
    "pd.set_option('precision', 3)\n",
    "TARGET_COLUMN = 'Activity_Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def choose_features(x_train, y_train, x_test, column_names):\n",
    "    \"\"\"\n",
    "    Selecting the features of high importance to reduce feature space.\n",
    "    :param x_train: Training set of features.\n",
    "    :param x_test: Test set of features.\n",
    "    :param y_train: Training target values\n",
    "    :param column_names: Names of columns in x\n",
    "    \"\"\"\n",
    "\n",
    "    # Random forest feature importance\n",
    "    clf = RandomForestRegressor(n_jobs=-1, random_state=1, n_estimators=20, max_depth=10)\n",
    "    # Random state has int value for non-random sampling\n",
    "    clf.fit(x_train, y_train)\n",
    "    feature_importance = clf.feature_importances_\n",
    "    scores_table = pd.DataFrame({'feature': column_names, 'scores':\n",
    "                                 feature_importance}).sort_values(by=['scores'], ascending=False)\n",
    "    scores = scores_table['scores'].tolist()\n",
    "    n_features = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    for n in n_features:\n",
    "        feature_scores = scores_table['feature'].tolist()\n",
    "        selected_features = feature_scores[:n]\n",
    "        x_train = pd.DataFrame(x_train, columns=column_names)\n",
    "        desired_x_train = x_train[selected_features]\n",
    "        x_test = pd.DataFrame(x_test, columns=column_names)\n",
    "        desired_x_test = x_test[selected_features]\n",
    "\n",
    "        desired_x_train.to_csv('./data/all_x_train_postprocessing_rfr_%d.csv' % n)\n",
    "        desired_x_test.to_csv('./data/all_x_test_postprocessing_rfr_%d.csv' % n)\n",
    "    pd.DataFrame(scores).to_csv('./data/all_feature_scores_rfr.csv')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def change_nan_infinite(dataframe):\n",
    "    \"\"\"\n",
    "    Replacing NaN and infinite values from the dataframe with zeros.\n",
    "    :param dataframe: Dataframe containing NaN and infinite values.\n",
    "    :return data: Data with no NaN or infinite values.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = dataframe.fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def run_models(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Driving all machine learning models as parallel processes.\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model_choice = int(input(\"Type your choice of model to be run:\" + \"\\n\" +\n",
    "                             \"1 for Linear Regression\" + \"\\n\" +\n",
    "                             \"2 for Neural Network\" + \"\\n\" +\n",
    "                             \"3 for Support Vector Machine\" + \"\\n\" +\n",
    "                             \"4 for Decision Tree\" + \"\\n\" +\n",
    "                             \"5 for Ridge Regression\" + \"\\n\" +\n",
    "                             \"6 for Bayesian Ridge Regression\" + \"\\n\" +\n",
    "                             \"7 for Lasso:\" + \"\\n\" +\n",
    "                             \"8 for Random Forest Regressor:\" + \"\\n\"\n",
    "                             ))\n",
    "    if model_choice == 1:\n",
    "        build_linear(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 2:\n",
    "        build_nn(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 3:\n",
    "        build_svm(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 4:\n",
    "        build_tree(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 5:\n",
    "        build_ridge(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 6:\n",
    "        build_bayesian_rr(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 7:\n",
    "        build_lasso(x_train, y_train, x_test, y_test, n_features)\n",
    "    elif model_choice == 8:\n",
    "        build_forest(x_train, y_train, x_test, y_test, n_features)\n",
    "    else:\n",
    "        print(\"Please choose from list of available models only\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_linear(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a decision trees regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_lr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_nn(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a regression neural network model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    net = NeuralNet(layers=[('input', InputLayer),\n",
    "                            ('hidden0', DenseLayer),\n",
    "                            ('hidden1', DenseLayer),\n",
    "                            ('output', DenseLayer)],\n",
    "                    input_shape=(None, x_train.shape[1]),  # Number of i/p nodes = number of columns in x\n",
    "                    hidden0_num_units=15,\n",
    "                    hidden0_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    hidden1_num_units=17,\n",
    "                    hidden1_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    output_num_units=1,  # Number of o/p nodes = number of columns in y\n",
    "                    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                    max_epochs=100,\n",
    "                    update_learning_rate=0.01,\n",
    "                    regression=True,\n",
    "                    verbose=1)\n",
    "\n",
    "    # Finding the optimal set of params for each variable in the training of the neural network\n",
    "    param_dist = {'hidden0_num_units':sp_randint(3, 30), 'hidden1_num_units':sp_randint(3, 30)}\n",
    "    clf = RandomizedSearchCV(estimator=net, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_nn_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(net, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_svm(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a support vector regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    clf = LinearSVR(random_state=1, dual=False, epsilon=0,\n",
    "                    loss='squared_epsilon_insensitive')\n",
    "    # Random state has int value for non-random sampling\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_svm_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_tree(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a decision trees regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model = DecisionTreeRegressor()\n",
    "    param_dist = {'max_depth': sp_randint(1, 15),\n",
    "                  'min_samples_split': sp_randint(2, 15)}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_dt_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_ridge(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a ridge regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = Ridge()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_rr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_bayesian_rr(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a Bayesian ridge regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_brr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_lasso(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a Lasso linear model with cross validation from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model = Lasso(random_state=1)\n",
    "    # Random state has int value for non-random sampling\n",
    "    param_dist = {'alpha': np.arange( 0.0001, 1, 0.001 ).tolist()}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=20, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_lasso_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def build_forest(x_train, y_train, x_test, y_test, n_features):\n",
    "    \"\"\"\n",
    "    Constructing a random forest regression model from input dataframe\n",
    "    :param x_train: features dataframe for model training\n",
    "    :param y_train: target dataframe for model training\n",
    "    :param x_test: features dataframe for model testing\n",
    "    :param y_test: target dataframe for model testing\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor()\n",
    "    param_dist = {'max_depth': sp_randint(1, 15),\n",
    "                  'min_samples_split': sp_randint(2, 15)}\n",
    "    clf = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                             n_iter=15, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Mean absolute error regression loss\n",
    "    mean_abs = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "    # Mean squared error regression loss\n",
    "    mean_sq = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    # Median absolute error regression loss\n",
    "    median_abs = sklearn.metrics.median_absolute_error(y_test, y_pred)\n",
    "    # R^2 (coefficient of determination) regression score function\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    # Explained variance regression score function\n",
    "    exp_var_score = sklearn.metrics.explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    with open('./trained_networks/all_rfr_%d_data.pkl' % n_features, 'wb') as results:\n",
    "        pickle.dump(clf, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(mean_sq, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(median_abs, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(r2, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(exp_var_score, results, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(y_pred, results, pickle.HIGHEST_PROTOCOL)\n",
    "    print(r2)\n",
    "    return\n",
    "\n",
    "def results():\n",
    "    df_mean_abs = pd.DataFrame()\n",
    "    df_mean_sq = pd.DataFrame()\n",
    "    df_median_abs = pd.DataFrame()\n",
    "    df_r2 = pd.DataFrame()\n",
    "    df_exp_var_score = pd.DataFrame()\n",
    "    lists = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    \n",
    "    for n_features in lists:\n",
    "        with open('./trained_networks/all_lr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear Regression', '%d' % n_features,  mean_abs)\n",
    "            df_mean_sq.set_value('Linear Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_nn_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            net = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_nn = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Neural Network', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Neural Network', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Neural Network', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Neural Network', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Neural Network', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_svm_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_svm = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Linear SVR', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Linear SVR', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Linear SVR', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Linear SVR', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Linear SVR', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_dt_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_dt = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Decision Tree', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Decision Tree', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Decision Tree', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Decision Tree', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Decision Tree', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_rr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_rr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_brr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_brr = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Bayesian Ridge Regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Bayesian Ridge Regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Bayesian Ridge Regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Bayesian Ridge Regression', '%d' % n_features, exp_var_score)\n",
    "            \n",
    "        with open('./trained_networks/all_lasso_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Lasso', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Lasso', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Lasso', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Lasso', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Lasso', '%d' % n_features, exp_var_score)\n",
    "\n",
    "        with open('./trained_networks/all_rfr_%d_data.pkl' % n_features, 'rb') as result:\n",
    "            clf = pickle.load(result)\n",
    "            mean_abs = pickle.load(result)\n",
    "            mean_sq = pickle.load(result)\n",
    "            median_abs = pickle.load(result)\n",
    "            r2 = pickle.load(result)\n",
    "            exp_var_score = pickle.load(result)\n",
    "            y_pred_lasso = pickle.load(result)\n",
    "            \n",
    "            df_mean_abs.set_value('Random Forest regression', '%d' % n_features, mean_abs)\n",
    "            df_mean_sq.set_value('Random Forest regression', '%d' % n_features, mean_sq)\n",
    "            df_median_abs.set_value('Random Forest regression', '%d' % n_features, median_abs)\n",
    "            df_r2.set_value('Random Forest regression', '%d' % n_features, r2)\n",
    "            df_exp_var_score.set_value('Random Forest regression', '%d' % n_features, exp_var_score)\n",
    "\n",
    "    return df_mean_abs, df_mean_sq, df_median_abs, df_r2, df_exp_var_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://s3-us-west-2.amazonaws.com/'\n",
    "                 'pphilip-usp-inhibition/data/df_preprocessing.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Copying column names to use after np array manipulation\n",
    "all_headers = list(df.columns.values)\n",
    "x_headers = list(df.columns.values)[:-1]\n",
    "\n",
    "# Train, validation and test split\n",
    "df_train, df_test = model_selection.train_test_split(df, test_size=0.25)\n",
    "# Reassign column name and index after randomized split\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)\n",
    "df_train = pd.DataFrame(df_train, columns=all_headers)\n",
    "df_test = pd.DataFrame(df_test, columns=all_headers)\n",
    "\n",
    "# Remove the classification column from the dataframe\n",
    "x_train = df_train.drop(TARGET_COLUMN, axis=1)\n",
    "x_test = df_test.drop(TARGET_COLUMN, axis=1)\n",
    "y_train = df_train[TARGET_COLUMN]\n",
    "y_test = df_test[TARGET_COLUMN]\n",
    "\n",
    "# Checking dataframe for NaN and infinite values\n",
    "x_train = change_nan_infinite(x_train)\n",
    "y_train = change_nan_infinite(y_train)\n",
    "x_test = change_nan_infinite(x_test)\n",
    "y_test = change_nan_infinite(y_test)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns=[TARGET_COLUMN])\n",
    "y_test = pd.DataFrame(y_test, columns=[TARGET_COLUMN])\n",
    "\n",
    "y_train.to_csv('./data/all_y_train_postprocessing.csv')\n",
    "y_test.to_csv('./data/all_y_test_postprocessing.csv')\n",
    "\n",
    "# Transform all column values to mean 0 and unit variance\n",
    "clf = sklearn.preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = clf.transform(x_train)\n",
    "x_test = clf.transform(x_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Feature selection and feature importance plot\n",
    "choose_features(x_train, y_train, x_test, x_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = int(input(\"Choose the number of features to be used in the model\" + \"\\n\" +\n",
    "                       \"Pick from 25, 50, 75, 100, 150, 200, 250, 300\" + \"\\n\"))\n",
    "x_train = pd.read_csv('./data/all_x_train_postprocessing_rfr_%d.csv' % n_features)\n",
    "x_test = pd.read_csv('./data/all_x_test_postprocessing_rfr_%d.csv' % n_features)\n",
    "y_train = pd.read_csv('./data/all_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/all_y_test_postprocessing.csv')\n",
    "x_train.drop(x_train.columns[0], axis=1, inplace=True)\n",
    "x_test.drop(x_test.columns[0], axis=1, inplace=True)\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "\n",
    "print(\"Generating models\")\n",
    "run_models(np.array(x_train), np.array(y_train).ravel(), np.array(x_test), np.array(y_test).ravel(), n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mean_abs, df_mean_sq, df_median_abs, df_r2, df_exp_var_score = results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1.451</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.471</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.468</td>\n",
       "      <td>1.462</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>1.413</td>\n",
       "      <td>1.398</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.431</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Neural Network             1.678  1.678  1.678  1.678  1.678  1.678  1.678   \n",
       "Linear SVR                 1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Decision Tree              1.451  1.470  1.470  1.470  1.470  1.456  1.456   \n",
       "Ridge Regression           1.464  1.463  1.464  1.462  1.465  1.466  1.470   \n",
       "Bayesian Ridge Regression  1.464  1.463  1.463  1.462  1.463  1.464  1.465   \n",
       "Lasso                      1.471  1.463  1.464  1.468  1.462  1.463  1.461   \n",
       "Random Forest regression   1.413  1.398  1.420  1.416  1.431  1.420  1.416   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          1.473  \n",
       "Neural Network             1.678  \n",
       "Linear SVR                 1.473  \n",
       "Decision Tree              1.448  \n",
       "Ridge Regression           1.473  \n",
       "Bayesian Ridge Regression  1.466  \n",
       "Lasso                      1.464  \n",
       "Random Forest regression   1.420  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "      <td>15.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>15.075</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.241</td>\n",
       "      <td>15.176</td>\n",
       "      <td>15.176</td>\n",
       "      <td>15.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.081</td>\n",
       "      <td>15.042</td>\n",
       "      <td>15.018</td>\n",
       "      <td>14.980</td>\n",
       "      <td>14.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>15.164</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.115</td>\n",
       "      <td>15.084</td>\n",
       "      <td>15.050</td>\n",
       "      <td>15.022</td>\n",
       "      <td>14.994</td>\n",
       "      <td>14.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>15.211</td>\n",
       "      <td>15.142</td>\n",
       "      <td>15.153</td>\n",
       "      <td>15.174</td>\n",
       "      <td>15.125</td>\n",
       "      <td>15.130</td>\n",
       "      <td>15.118</td>\n",
       "      <td>15.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>14.608</td>\n",
       "      <td>14.504</td>\n",
       "      <td>14.783</td>\n",
       "      <td>14.692</td>\n",
       "      <td>14.752</td>\n",
       "      <td>14.631</td>\n",
       "      <td>14.689</td>\n",
       "      <td>14.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               25      50      75     100     150     200  \\\n",
       "Linear Regression          15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Neural Network             15.349  15.349  15.349  15.349  15.349  15.349   \n",
       "Linear SVR                 15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Decision Tree              15.075  15.241  15.241  15.241  15.241  15.176   \n",
       "Ridge Regression           15.164  15.130  15.115  15.081  15.042  15.018   \n",
       "Bayesian Ridge Regression  15.164  15.130  15.115  15.084  15.050  15.022   \n",
       "Lasso                      15.211  15.142  15.153  15.174  15.125  15.130   \n",
       "Random Forest regression   14.608  14.504  14.783  14.692  14.752  14.631   \n",
       "\n",
       "                              250     300  \n",
       "Linear Regression          14.980  14.964  \n",
       "Neural Network             15.349  15.349  \n",
       "Linear SVR                 14.980  14.961  \n",
       "Decision Tree              15.176  15.202  \n",
       "Ridge Regression           14.980  14.962  \n",
       "Bayesian Ridge Regression  14.994  14.972  \n",
       "Lasso                      15.118  15.144  \n",
       "Random Forest regression   14.689  14.728  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Neural Network             1.000  1.000  1.000  1.000  1.000  1.000  1.000   \n",
       "Linear SVR                 0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Decision Tree              0.490  0.547  0.547  0.547  0.547  0.490  0.490   \n",
       "Ridge Regression           0.726  0.720  0.720  0.713  0.709  0.706  0.711   \n",
       "Bayesian Ridge Regression  0.726  0.721  0.722  0.713  0.709  0.708  0.707   \n",
       "Lasso                      0.737  0.726  0.727  0.734  0.719  0.719  0.717   \n",
       "Random Forest regression   0.553  0.527  0.546  0.552  0.581  0.542  0.542   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.711  \n",
       "Neural Network             1.000  \n",
       "Linear SVR                 0.711  \n",
       "Decision Tree              0.632  \n",
       "Ridge Regression           0.711  \n",
       "Bayesian Ridge Regression  0.709  \n",
       "Lasso                      0.723  \n",
       "Random Forest regression   0.556  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_median_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Neural Network            -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003   \n",
       "Linear SVR                 0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Decision Tree              0.020  0.009  0.009  0.009  0.009  0.013  0.013   \n",
       "Ridge Regression           0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Bayesian Ridge Regression  0.014  0.016  0.017  0.019  0.021  0.023  0.025   \n",
       "Lasso                      0.011  0.016  0.015  0.013  0.017  0.016  0.017   \n",
       "Random Forest regression   0.050  0.057  0.039  0.045  0.041  0.049  0.045   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.027  \n",
       "Neural Network            -0.003  \n",
       "Linear SVR                 0.027  \n",
       "Decision Tree              0.012  \n",
       "Ridge Regression           0.027  \n",
       "Bayesian Ridge Regression  0.027  \n",
       "Lasso                      0.015  \n",
       "Random Forest regression   0.042  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest regression</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              25     50     75    100    150    200    250  \\\n",
       "Linear Regression          0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Neural Network             0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "Linear SVR                 0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Decision Tree              0.020  0.009  0.009  0.009  0.009  0.013  0.013   \n",
       "Ridge Regression           0.014  0.016  0.017  0.019  0.022  0.024  0.026   \n",
       "Bayesian Ridge Regression  0.014  0.016  0.017  0.019  0.021  0.023  0.025   \n",
       "Lasso                      0.011  0.016  0.015  0.013  0.017  0.016  0.017   \n",
       "Random Forest regression   0.050  0.057  0.039  0.045  0.041  0.049  0.045   \n",
       "\n",
       "                             300  \n",
       "Linear Regression          0.027  \n",
       "Neural Network             0.000  \n",
       "Linear SVR                 0.027  \n",
       "Decision Tree              0.012  \n",
       "Ridge Regression           0.027  \n",
       "Bayesian Ridge Regression  0.027  \n",
       "Lasso                      0.015  \n",
       "Random Forest regression   0.042  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_var_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 300\n",
    "x_train = pd.read_csv('./data/all_x_train_postprocessing_rfr_%d.csv' % n_features)\n",
    "x_test = pd.read_csv('./data/all_x_test_postprocessing_rfr_%d.csv' % n_features)\n",
    "y_train = pd.read_csv('./data/all_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/all_y_test_postprocessing.csv')\n",
    "x_train.drop(x_train.columns[0], axis=1, inplace=True)\n",
    "x_test.drop(x_test.columns[0], axis=1, inplace=True)\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "plots.plot_features(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('./data/all_y_train_postprocessing.csv')\n",
    "y_test = pd.read_csv('./data/all_y_test_postprocessing.csv')\n",
    "y_train.drop(y_train.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[0], axis=1, inplace=True)\n",
    "plots.plot_y_dist(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genalgo.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
